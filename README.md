# CVPR2020
[CVPR2020 paper list](http://cvpr2020.thecvf.com/program/main-conference)

## Table of Contents
  - [Visual-Language Grounding](#visual-language-grounding)
  - [Object-Detection](#object-detection)
  - [Pose-Estimation](#pose-estimation)


### Visual-Language Grounding:
1. Mihir Prabhudesai, Hsiao-Yu Fish Tung, Syed Ashar Javed, et al. **Embodied Language Grounding With 3D Visual Feature Representations.** [[Paper]](https://arxiv.org/pdf/1910.01210.pdf) [[Code]]() - Nuri

### Object-Detection
1. Wu Jialian, Zhou Chunluan, Yang Ming, et al. **Temporal-Context Enhanced Detection of Heavily Occluded Pedestrians.** [[Paper]](https://cse.buffalo.edu/~jsyuan/papers/2020/TFAN.pdf) - Kyungdo

2. Perez-Rua, Juan-Manuel, et al. **Incremental Few-Shot Object Detection.** [[Paper]](https://arxiv.org/pdf/2003.04668.pdf) - Hogun

3. Zhu, Pengkai, Hanxiao Wang, and Venkatesh Saligrama. **Dont Even Look Once: Synthesizing Features for Zero-Shot Detection.** [[Paper]](https://arxiv.org/pdf/1911.07933.pdf) - Hogun

### Pose-Estimation
1. He, Yisheng, et al. **PVN3D: A Deep Point-wise 3D Keypoints Voting Network for 6DoF Pose Estimation.** [[Paper]](https://arxiv.org/pdf/1911.04231.pdf) [[Code]](https://github.com/ethnhe/PVN3D) - Hogun

2. Liu, Xingyu, et al. **KeyPose: Multi-View 3D Labeling and Keypoint Estimationfor Transparent Objects.** [[Paper]](https://arxiv.org/pdf/1912.02805.pdf) [[Code]](https://sites.google.com/view/keypose) - Hogun
